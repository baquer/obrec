# obrec
obrec is an app that enable visually individuals to gain more independence in daily tasks like grocery shopping,
self-navigating in indoor environments, and reading. It uses Machine Learning to enable a visually impaired user
to click a photo of virtually any object or piece of text, and then speaks aloud a description of the object in an image
or dictate any text in the image to the user.
In this I use ‘Inceptionv3’ ML Model ,and a pip file that detects the image and gives output in the form of text and speak about that object .
‘Siri’ privacy is enabled to open the app easily .Privacy control is enable for the security issue 
We can add this app to Health in our iOS Devices whether the device is iPhone or iPad or MacBook.
‘Project Oxford face’ pod is used for face detection and I am still implementing the code for face detection because its difficult to write a 
code in a new language like ‘Swift’
